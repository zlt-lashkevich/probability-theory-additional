#import "@preview/cetz:0.4.2": canvas, draw

#set page(paper: "a4", margin: 25mm)
#set text(lang: "ru", font: "New Computer Modern", size: 11pt)
#set par(justify: true, leading: 0.65em)
#show selector(<nonumber>): set heading(numbering: none)

#align(center)[
  #text(size: 17pt, weight: "bold")[Хитрый лис Иссерлис]
  #v(0.3em)
  #text(size: 11pt)[Моменты произведений координат гауссовского вектора]
]

#v(1em)

= Постановка задачи

Пусть случайный вектор $bold(X) = (X_1, X_2, dots, X_n)$ распределён нормально:
$
bold(X) tilde cal(N)_n (bold(mu), bold(C)),
$
где $bold(mu) = (mu_1, dots, mu_n)^top$ — вектор средних, 
$bold(C) = [C_(i j)]$ — ковариационная матрица.

*Базовое соотношение:*
$
E[X_i X_j] = mu_i mu_j + C_(i j)
$

*Задача:* найти $E[X_1 X_2 dots.c X_n]$ для произвольного $n$.


= Формула Иссерлиса (предварительная формулировка)

#box(
  width: 100%,
  fill: rgb("#e8f4f8"),
  inset: 12pt,
  radius: 4pt,
)[
  *Утверждение:* Для гауссовского вектора
  $
  E[X_1 X_2 dots.c X_n] = h(bold(mu), bold(C))
  $
  где $h$ — полином, состоящий из слагаемых вида:
  $
  mu_(i_1) mu_(i_2) dots.c mu_(i_k) dot C_(j_1 j_2) C_(j_3 j_4) dots.c C_(j_(n-k-1) j_(n-k))
  $
  причём все коэффициенты равны $1$.
]

= Доказательство по шагам

== Шаг 1: Общая структура — функция от $(bold(mu), bold(C))$

*Утверждение:* $E[X_1 X_2 dots.c X_n] = h(bold(mu), bold(C))$

*Обоснование:*

Распределение гауссовского вектора полностью определяется парой $(bold(mu), bold(C))$.

Следовательно, любой момент — функция только этих параметров:
$
E[X_1 X_2 dots.c X_n] = h(bold(mu), bold(C))
$

*Размерностный анализ:*

- $[E[X_1 dots.c X_n]] = [X]^n$
- $[mu_i] = [X]$
- $[C_(i j)] = [X]^2$

$arrow.r.double$ Каждое слагаемое содержит $k$ множителей $mu$ и $(n-k)/2$ множителей $C$,
где $k + 2 dot (n-k)/2 = n$, т.е. $k$ и $n$ одной чётности.

--------------------------------------------------------------------------------

== Шаг 2: Структура зависимости от $bold(mu)$

*Утверждение:* $h(bold(mu), bold(C))$ — полином по $mu_1, dots, mu_n$.

*Доказательство:*

Запишем $X_i = mu_i + Y_i$, где $Y_i$ — центрированные ($E[Y_i] = 0$).

$
E[X_1 dots.c X_n] = E[(mu_1 + Y_1)(mu_2 + Y_2) dots.c (mu_n + Y_n)]
$

Раскрываем скобки:
$
= sum_(S subset.eq {1, dots, n}) product_(i in S) mu_i dot E[product_(j in.not S) Y_j]
$

*Пример для $n = 3$:*
$
E[X_1 X_2 X_3] &= mu_1 mu_2 mu_3 \
&+ mu_1 E[Y_2 Y_3] + mu_2 E[Y_1 Y_3] + mu_3 E[Y_1 Y_2] \
&+ E[Y_1 Y_2 Y_3]
$

Поскольку $E[Y_1 Y_2 Y_3] = 0$ (нечётный момент центрированных), получаем:
$
E[X_1 X_2 X_3] = mu_1 mu_2 mu_3 + mu_1 C_(23) + mu_2 C_(13) + mu_3 C_(12)
$

--------------------------------------------------------------------------------

== Шаг 3: Зависимость от диагональных элементов $C_(i i)$ — добавляем шум

*Идея:* добавим независимый шум $tilde(Z) tilde cal(N)(0, sigma^2)$ к одной координате.

Пусть $tilde(Z)$ независим от $bold(X)$. Определим:
$
tilde(X)_1 = X_1 + tilde(Z), quad tilde(X)_i = X_i "для" i >= 2
$

*Вычислим новые ковариации:*

$
"Var"(tilde(X)_1) = "Var"(X_1) + "Var"(tilde(Z)) = C_(11) + sigma^2
$

$
"Cov"(tilde(X)_1, X_2) = "Cov"(X_1 + tilde(Z), X_2) = "Cov"(X_1, X_2) + underbrace("Cov"(tilde(Z), X_2), = 0) = C_(12)
$

*Новая ковариационная матрица:*

$
bold(C) = mat(
  C_(11), C_(12), C_(13), dots;
  C_(12), C_(22), C_(23), dots;
  C_(13), C_(23), C_(33), dots;
  dots.v, dots.v, dots.v, dots.down;
)
quad arrow.r quad
tilde(bold(C)) = mat(
  C_(11) + sigma^2, C_(12), C_(13), dots;
  C_(12), C_(22), C_(23), dots;
  C_(13), C_(23), C_(33), dots;
  dots.v, dots.v, dots.v, dots.down;
)
$

*Ключевое соотношение:*

$
E[tilde(X)_1 X_2 X_3 dots.c X_n] = h(bold(mu), tilde(bold(C)))
$

*С другой стороны,* раскроем напрямую:

$
E[tilde(X)_1 X_2 dots.c X_n] &= E[(X_1 + tilde(Z)) X_2 dots.c X_n] \
&= E[X_1 X_2 dots.c X_n] + E[tilde(Z)] dot E[X_2 dots.c X_n] \
&= E[X_1 X_2 dots.c X_n] + 0
$

*Вывод:* При изменении $C_(11) arrow.r C_(11) + sigma^2$ момент *не меняется*!

$
h(bold(mu), tilde(bold(C))) = h(bold(mu), bold(C))
$

$arrow.r.double$ Функция $h$ *не зависит* от $C_(11)$ (и аналогично от любого $C_(i i)$).

#box(
  width: 100%,
  fill: rgb("#fff4e6"),
  inset: 10pt,
  radius: 4pt,
)[
  *Вывод Шага 3:*
  
  В формуле Иссерлиса для $E[X_1 X_2 dots.c X_n]$ с *различными* индексами
  диагональные элементы $C_(i i)$ *не появляются*.
  
  Они появляются только когда индекс повторяется (например, $E[X_1^2 X_2]$).
]

--------------------------------------------------------------------------------

== Шаг 4: Зависимость от $C_(12)$ — добавляем общий шум к $X_1$ и $X_2$

*Идея:* чтобы изменить *ковариацию* $C_(12)$, добавим *общий* шум.

Пусть $tilde(Z) tilde cal(N)(0, sigma^2)$ независим от $bold(X)$.

Определим:
$
tilde(X)_1 = X_1 + tilde(Z), quad tilde(X)_2 = X_2 + tilde(Z), quad tilde(X)_i = X_i "для" i >= 3
$

*Вычислим новые ковариации:*

$
"Var"(tilde(X)_1) = "Var"(X_1) + "Var"(tilde(Z)) = C_(11) + sigma^2
$

$
"Var"(tilde(X)_2) = "Var"(X_2) + "Var"(tilde(Z)) = C_(22) + sigma^2
$

$
"Cov"(tilde(X)_1, tilde(X)_2) &= "Cov"(X_1 + tilde(Z), X_2 + tilde(Z)) \
&= "Cov"(X_1, X_2) + "Cov"(X_1, tilde(Z)) + "Cov"(tilde(Z), X_2) + "Cov"(tilde(Z), tilde(Z)) \
&= C_(12) + 0 + 0 + sigma^2 = C_(12) + sigma^2
$

$
"Cov"(tilde(X)_1, X_3) = "Cov"(X_1 + tilde(Z), X_3) = C_(13) + 0 = C_(13)
$

*Новая ковариационная матрица:*

$
tilde(bold(C)) = mat(
  C_(11) + sigma^2, C_(12) + sigma^2, C_(13), dots;
  C_(12) + sigma^2, C_(22) + sigma^2, C_(23), dots;
  C_(13), C_(23), C_(33), dots;
  dots.v, dots.v, dots.v, dots.down;
)
$


*Теперь вычислим момент напрямую:*

$
E[tilde(X)_1 tilde(X)_2 X_3 dots.c X_n] &= E[(X_1 + tilde(Z))(X_2 + tilde(Z)) X_3 dots.c X_n] \
&= E[X_1 X_2 X_3 dots.c X_n] + E[X_1 tilde(Z) X_3 dots.c X_n] \
&quad + E[tilde(Z) X_2 X_3 dots.c X_n] + E[tilde(Z)^2 X_3 dots.c X_n]
$

Используем независимость $tilde(Z)$ от $bold(X)$:

$
&= E[X_1 X_2 dots.c X_n] + E[tilde(Z)] dot E[X_1 X_3 dots.c X_n] \
&quad + E[tilde(Z)] dot E[X_2 X_3 dots.c X_n] + E[tilde(Z)^2] dot E[X_3 dots.c X_n] \
&= E[X_1 X_2 dots.c X_n] + 0 + 0 + sigma^2 dot E[X_3 dots.c X_n]
$

*Итого:*

$
E[tilde(X)_1 tilde(X)_2 X_3 dots.c X_n] = E[X_1 X_2 dots.c X_n] + sigma^2 dot E[X_3 dots.c X_n]
$

*С другой стороны,* по функции $h$:

$
h(bold(mu), tilde(bold(C))) = h(bold(mu), bold(C)) + (partial h) / (partial C_(11)) sigma^2 + (partial h) / (partial C_(22)) sigma^2 + (partial h) / (partial C_(12)) sigma^2 + (partial h) / (partial C_(21)) sigma^2 + O(sigma^4)
$

Но из Шага 3: $(partial h) / (partial C_(11)) = (partial h) / (partial C_(22)) = 0$.

И $C_(12) = C_(21)$, поэтому:

$
h(bold(mu), tilde(bold(C))) = h(bold(mu), bold(C)) + 2 (partial h) / (partial C_(12)) sigma^2 + O(sigma^4)
$

*Сравнивая:*

$
2 (partial h) / (partial C_(12)) sigma^2 = sigma^2 dot E[X_3 dots.c X_n]
$

$
arrow.r.double quad (partial h) / (partial C_(12)) = 1/2 E[X_3 dots.c X_n]
$

#box(
  width: 100%,
  fill: rgb("#e8f8e8"),
  inset: 10pt,
  radius: 4pt,
)[
  *Вывод Шага 4:*
  
  $
  (partial h) / (partial C_(12)) = 1/2 E[X_3 X_4 dots.c X_n]
  $
  
  Это означает: функция $h$ *линейна* по каждому $C_(i j)$,
  и коэффициент при $C_(12)$ пропорционален моменту *оставшихся* переменных.
]

--------------------------------------------------------------------------------

== Шаг 5.1: Все коэффициенты равны 1 — метод специальных подстановок

*Идея:* выберем *конкретные* значения $bold(mu)$ и $bold(C)$, чтобы «выключить» 
все слагаемые кроме одного и проверить его коэффициент.

=== Подстановка 1: Проверка коэффициента при $C_(12) C_(34)$

Рассмотрим $E[X_1 X_2 X_3 X_4]$ для центрированного случая ($bold(mu) = bold(0)$).

По формуле (которую проверяем):
$
E[X_1 X_2 X_3 X_4] = alpha dot C_(12) C_(34) + beta dot C_(13) C_(24) + gamma dot C_(14) C_(23)
$

*Специальная ковариационная матрица:*

Положим:
$
bold(C) = mat(
  1, c, 0, 0;
  c, 1, 0, 0;
  0, 0, 1, c;
  0, 0, c, 1;
)
$

где $c in (0, 1)$ — параметр.

При такой матрице:
- $C_(12) = C_(34) = c$
- $C_(13) = C_(14) = C_(23) = C_(24) = 0$

Тогда:
$
E[X_1 X_2 X_3 X_4] = alpha dot c^2 + beta dot 0 + gamma dot 0 = alpha c^2
$

*Вычислим напрямую:*

Вектор $(X_1, X_2)$ независим от $(X_3, X_4)$.

$
E[X_1 X_2 X_3 X_4] = E[X_1 X_2] dot E[X_3 X_4] = C_(12) dot C_(34) = c^2
$

*Сравнивая:* $alpha c^2 = c^2$ $arrow.r.double$ $alpha = 1 checkmark $ 

=== Подстановка 2: Проверка коэффициента при $mu_1 mu_2 C_(34)$

Рассмотрим $E[X_1 X_2 X_3 X_4]$ для нецентрированного случая.

*Специальные параметры:*

$
bold(mu) = (a, a, 0, 0)^top, quad
bold(C) = mat(
  1, 0, 0, 0;
  0, 1, 0, 0;
  0, 0, 1, c;
  0, 0, c, 1;
)
$

При этом:
- $mu_1 = mu_2 = a$, $mu_3 = mu_4 = 0$
- $C_(12) = C_(13) = C_(14) = C_(23) = C_(24) = 0$
- $C_(34) = c$

Ожидаемая форма:
$
E[X_1 X_2 X_3 X_4] = beta dot mu_1 mu_2 C_(34) + dots = beta a^2 c + dots
$

*Вычислим напрямую:*

$(X_1, X_2)$ независимы от $(X_3, X_4)$, и $X_1, X_2$ независимы между собой.

$
E[X_1 X_2 X_3 X_4] &= E[X_1] dot E[X_2] dot E[X_3 X_4] \
&= a dot a dot C_(34) = a^2 c
$

*Сравнивая:* $beta a^2 c = a^2 c$ $arrow.r.double$ $beta = 1 checkmark$

=== Общая схема подстановок

#box(
  width: 100%,
  fill: rgb("#f0f8ff"),
  inset: 10pt,
  radius: 4pt,
)[
  *Алгоритм проверки коэффициента при слагаемом $mu_(i_1) dots.c mu_(i_k) C_(j_1 j_2) dots.c C_(j_(m-1) j_m)$:*
  
  1. Положить $mu_i = a$ для $i in {i_1, dots, i_k}$, иначе $mu_i = 0$
  
  2. Положить $C_(j_(2ell-1), j_(2ell)) = c$ для нужных пар, остальные $C_(i j) = 0$ для $i != j$
  
  3. Вычислить $E[X_1 dots.c X_n]$ напрямую (используя независимость)
  
  4. Сравнить с $"коэфф" dot a^k c^((n-k)/2)$
  
  $arrow.r.double$ Коэффициент всегда равен $1$
]

--------------------------------------------------------------------------------

== Шаг 5.2: Метод индукция по $n$ с использованием зашумления

Если шум $Z tilde N(0, 1)$

*База:* $n = 2$
$
E[X_1 X_2] = mu_1 mu_2 + C_(12)
$
Коэффициенты: $1$ при $mu_1 mu_2$ и $1$ при $C_(12)$

*Индуктивный переход:*

Рассмотрим момент $M = E[X_1^2 X_2 dots.c X_n]$ (для простоты).

Добавим шум к $X_1$: $tilde(X)_1 = X_1 + sqrt(t) Z$

$
M(t) = E[(X_1 + sqrt(t) Z)^2 X_2 dots.c X_n]
$

$
= E[X_1^2 X_2 dots.c X_n] + t dot E[Z^2] dot E[X_2 dots.c X_n]
$

(используем независимость $Z$ от $X_2, dots, X_n$)

$
= M(0) + t dot E[X_2 dots.c X_n]
$

*С другой стороны,* по формуле $M = h(bold(mu), bold(C))$:

$
M(t) = h(bold(mu), bold(C)|_(C_(11) -> C_(11) + t))
$

$
(d M) / (d t) |_(t=0) = (partial h) / (partial C_(11))
$

*Сравниваем:*

$
(partial h) / (partial C_(11)) = E[X_2 dots.c X_n]
$

По предположению индукции, $E[X_2 dots.c X_n]$ имеет все коэффициенты равные $1$.

$arrow.r.double$ В $h$ коэффициент при каждом слагаемом, содержащем $C_(11)$, равен $1$.

Повторяя для всех $C_(i j)$, получаем: *все* коэффициенты равны $1$.


=  При чём здесь нормальное распределение?

#box(
  width: 100%,
  fill: rgb("#fff4e6"),
  inset: 12pt,
  radius: 4pt,
)[
  *Ключевой момент:* Мы использовали нормальность в двух местах:
  
  1. *Шаг 1:* распределение полностью определяется $(bold(mu), bold(C))$
  
  2. *Шаги 3–4:* устойчивость относительно добавления гауссовского шума:
  $
  X_i + tilde(Z) tilde cal(N)(mu_i, C_(i i) + sigma^2)
  $
  
  Гауссовский вектор *остаётся гауссовским* при добавлении независимого
  гауссовского шума — это *поворот* в расширенном пространстве.
]

*Связь с аксиомой Гермеля–Максвелла:*

В пространстве $(X_1, tilde(Z))$ преобразование
$
tilde(X)_1 = X_1 + tilde(Z) = (1, 1) dot vec(X_1, tilde(Z))
$
— это *проекция* на направление $(1, 1)$.

По аксиоме Гермеля–Максвелла:
- Совместное распределение $(X_1, tilde(Z))$ изотропно
- Проекция на любое направление — снова гауссова

*Для негауссовских распределений:*

- Добавление шума *не сохраняет* форму распределения
- Появляются ненулевые кумулянты $kappa_3, kappa_4, dots$
- Формула Иссерлиса *неверна*


#box(
  width: 100%,
  fill: rgb("#e8f8e8"),
  inset: 12pt,
  radius: 4pt,
)[
  *Теорема Иссерлиса формально:*
  
  Для гауссовского вектора $(X_1, dots, X_n) tilde cal(N)(bold(mu), bold(C))$:
  
  $
  E[X_1 X_2 dots.c X_n] = sum_("разбиения") product_("одиночки" {i}) mu_i dot product_("пары" (i,j)) C_(i j)
  $
  
  где сумма берётся по всем способам разбить $\{1, dots, n\}$ на:
  - «одиночки» $arrow.r$ вносят $mu_i$
  - «пары» $arrow.r$ вносят $C_(i j)$
  
  *Все коэффициенты равны 1*
]